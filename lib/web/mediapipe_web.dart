import 'dart:js' as js;
import 'dart:convert';
import 'dart:async';
import 'package:camera/camera.dart';
import 'package:flutter/foundation.dart';
import '../common/mediapipe_interface.dart';

/// MediaPipe ë™ì‘ ëª¨ë“œ
enum MediaPipeMode {
  loading,        // ì´ˆê¸° ë¡œë”© ì¤‘
  fullMediaPipe,  // ì™„ì „í•œ MediaPipe ë™ì‘
  manualLoading,  // Vision ì´ˆê¸°í™”ëŠ” ì‹¤íŒ¨í–ˆì§€ë§Œ SDK ë¡œë“œë¨, ìˆ˜ë™ ëª¨ë¸ ë¡œë”©
  stubMode,       // Mock ë°ì´í„° ëª¨ë“œ
}

/// ì›¹ í”Œë«í¼ìš© MediaPipe êµ¬í˜„ì²´
class MediaPipeWeb implements MediaPipeInterface {
  /// MediaPipe ì„¤ì •
  final MediaPipeConfig config;

  /// í˜„ì¬ ëª¨ë¸ ë¡œë”© ìƒíƒœ
  bool _isModelLoaded = false;

  /// í˜„ì¬ ì¶”ë¡  ëª¨ë“œ
  InferenceMode _currentMode = InferenceMode.landmark;
  
  /// MediaPipe ëª¨ë“œ ìƒíƒœ
  MediaPipeMode _currentMediaPipeMode = MediaPipeMode.loading;
  
  /// stub ëª¨ë“œ ì—¬ë¶€ (MediaPipe SDK ë¡œë”© ì‹¤íŒ¨ì‹œ)
  bool _isStubMode = false;

  MediaPipeWeb({
    this.config = const MediaPipeConfig(),
  });

  @override
  Future<void> initialize() async {
    try {
      debugPrint('ğŸ” Checking MediaPipe Web SDK loading...');
      
      // MediaPipe SDK ë¡œë”© ëŒ€ê¸° (ìµœëŒ€ 15ì´ˆ)
      for (int i = 0; i < 150; i++) {
        await Future.delayed(const Duration(milliseconds: 100));
        
        // ë¡œë”© ì„±ê³µ í™•ì¸
        final mediaLoadedBool = js.context['MediaPipeLoaded'];
        final mediaError = js.context['MediaPipeError'];
        
        if (i % 10 == 0) { // 1ì´ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
          debugPrint('Attempt ${i+1}/150: MediaPipeLoaded=$mediaLoadedBool, Error=$mediaError');
        }
        
        if (mediaLoadedBool == true) {
          // MediaPipe SDKê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë¨
          final tasksVision = js.context['MediaPipeTasksVision'];
          if (tasksVision != null) {
            debugPrint('âœ… MediaPipe Web SDK loaded successfully');
            
            // Vision ì´ˆê¸°í™” ì‹œë„ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
            try {
              bool initSuccess = false;
              int retryCount = 0;
              const maxRetries = 2;
              
              while (!initSuccess && retryCount <= maxRetries) {
                if (retryCount > 0) {
                  debugPrint('ğŸ”„ Retrying MediaPipe Vision initialization (attempt ${retryCount + 1}/${maxRetries + 1})...');
                  await Future.delayed(Duration(seconds: 2 * retryCount)); // ë°±ì˜¤í”„ ì§€ì—°
                }
                
                initSuccess = await _initializeVision();
                
                if (initSuccess) {
                  debugPrint('âœ… MediaPipe Vision initialized successfully - FULL MEDIAPIPE MODE');
                  _currentMediaPipeMode = MediaPipeMode.fullMediaPipe;
                  _isStubMode = false;
                  return;
                } else {
                  retryCount++;
                  if (retryCount <= maxRetries) {
                    debugPrint('âš ï¸ Vision initialization failed, will retry in ${2 * retryCount} seconds...');
                  }
                }
              }
              
              // ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ - fallback ì‹œë„
              debugPrint('âŒ MediaPipe Vision initialization failed after ${maxRetries + 1} attempts');
              debugPrint('ğŸ”„ Attempting fallback initialization method...');
              
              final fallbackSuccess = await _initializeVisionFallback();
              if (fallbackSuccess) {
                debugPrint('âœ… Fallback initialization successful - FULL MEDIAPIPE MODE');
                _currentMediaPipeMode = MediaPipeMode.fullMediaPipe;
                _isStubMode = false;
                return;
              }
              
              debugPrint('âŒ Fallback initialization also failed');
              debugPrint('ğŸ”§ Switching to MANUAL LOADING MODE (SDK available, manual model loading)');
              _currentMediaPipeMode = MediaPipeMode.manualLoading;
              _isStubMode = false;
              return;
              
            } catch (e) {
              debugPrint('âŒ MediaPipe Vision initialization error: $e');
              debugPrint('ğŸ”§ Switching to MANUAL LOADING MODE (SDK available, manual model loading)');
              _currentMediaPipeMode = MediaPipeMode.manualLoading;
              _isStubMode = false;
              return;
            }
          }
        }
        
        if (mediaError != null) {
          debugPrint('âš ï¸ MediaPipe SDK loading failed: $mediaError');
          debugPrint('ğŸ”„ Switching to STUB MODE (mock data)');
          _currentMediaPipeMode = MediaPipeMode.stubMode;
          _isStubMode = true;
          return;
        }
      }
      
      // íƒ€ì„ì•„ì›ƒ
      debugPrint('â° MediaPipe SDK loading timeout');
      debugPrint('ğŸ”„ Switching to STUB MODE (mock data)');
      _currentMediaPipeMode = MediaPipeMode.stubMode;
      _isStubMode = true;
      
    } catch (e) {
      debugPrint('âŒ MediaPipe Web initialization failed: $e');
      debugPrint('ğŸ”„ Switching to STUB MODE (mock data)');
      _currentMediaPipeMode = MediaPipeMode.stubMode;
      _isStubMode = true;
    }
  }

  /// MediaPipe Vision ì´ˆê¸°í™”
  Future<bool> _initializeVision() async {
    try {
      // JavaScript í•¨ìˆ˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
      if (!js.context.hasProperty('initializeMediaPipeVisionSync')) {
        debugPrint('âŒ JavaScript initialization function not found');
        return false;
      }
      
      // ìƒíƒœ ì´ˆê¸°í™” ë° ì´ˆê¸°í™” ì‹œì‘
      js.context['visionInitialized'] = false;
      js.context['visionInitializationFailed'] = false;
      js.context['vision'] = null;
      
      final initResult = js.context.callMethod('initializeMediaPipeVisionSync');
      if (initResult != 'started') {
        debugPrint('âŒ Failed to start vision initialization');
        return false;
      }
      
      // ì´ˆê¸°í™” ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 20ì´ˆ)
      for (int i = 0; i < 200; i++) {
        await Future.delayed(const Duration(milliseconds: 100));
        
        final visionInitialized = js.context['visionInitialized'];
        final visionFailed = js.context['visionInitializationFailed'];
        final visionReady = js.context['vision'] != null;
        final mediaError = js.context['MediaPipeError'];
        
        // ì£¼ê¸°ì  ìƒíƒœ ë¡œê·¸ (5ì´ˆë§ˆë‹¤)
        if (i % 50 == 0) {
          debugPrint('Vision status: initialized=$visionInitialized, failed=$visionFailed');
        }
        
        // ì„±ê³µ í™•ì¸
        if (visionInitialized == true && visionReady) {
          debugPrint('âœ… MediaPipe Vision initialized successfully');
          return true;
        }
        
        // ì‹¤íŒ¨ í™•ì¸
        if (visionFailed == true || (mediaError != null && mediaError != false)) {
          debugPrint('âŒ MediaPipe Vision initialization failed');
          return false;
        }
      }
      
      debugPrint('â° Vision initialization timeout');
      return false;
    } catch (e) {
      debugPrint('âŒ Vision initialization error: $e');
      return false;
    }
  }

  /// Fallback Vision ì´ˆê¸°í™” ë©”ì„œë“œ
  Future<bool> _initializeVisionFallback() async {
    try {
      debugPrint('ğŸ”„ Starting fallback MediaPipe Vision initialization...');
      
      // Fallback í•¨ìˆ˜ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
      final hasFallbackFunction = js.context.hasProperty('initializeMediaPipeVisionFallback');
      if (!hasFallbackFunction) {
        debugPrint('âŒ Fallback function not available');
        return false;
      }
      
      // ìƒíƒœ ì´ˆê¸°í™”
      js.context['visionInitialized'] = false;
      js.context['visionInitializationFailed'] = false;
      
      // Fallback í•¨ìˆ˜ í˜¸ì¶œ (async)
      final fallbackResult = await js.context.callMethod('initializeMediaPipeVisionFallback');
      debugPrint('ğŸ¯ Fallback initialization result: $fallbackResult');
      
      // ê²°ê³¼ í™•ì¸ì„ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
      for (int i = 0; i < 50; i++) {
        await Future.delayed(const Duration(milliseconds: 100));
        
        final visionInitialized = js.context['visionInitialized'];
        final visionFailed = js.context['visionInitializationFailed'];
        final visionReady = js.context['vision'] != null;
        
        if (visionInitialized == true && visionReady) {
          debugPrint('âœ… Fallback MediaPipe Vision initialized and ready');
          return true;
        }
        
        if (visionFailed == true) {
          debugPrint('âŒ Fallback MediaPipe Vision initialization failed');
          return false;
        }
      }
      
      debugPrint('â° Fallback initialization timeout');
      return false;
      
    } catch (e) {
      debugPrint('âŒ Fallback initialization error: $e');
      return false;
    }
  }

  @override
  Future<bool> loadModel(InferenceMode mode) async {
    try {
      debugPrint('ğŸ”„ Loading ${mode.name} model for web...');
      
      // ì›¹ì—ì„œëŠ” ëª¨ë¸ ë¡œë”©ì„ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ JavaScript ëª¨ë¸ ë¡œë”©ì€ ì¶”ë¡  ì‹œì— ìˆ˜í–‰)
      await Future.delayed(const Duration(seconds: 2));
      
      _isModelLoaded = true;
      _currentMode = mode;
      
      debugPrint('âœ… Web ${mode.name} model loaded successfully');
      return true;
      
    } catch (e) {
      debugPrint('âŒ Web model loading error: $e');
      _isModelLoaded = false;
      return false;
    }
  }

  @override
  Future<MediaPipeResult> detectLandmarks({
    required CameraImage? image,
  }) async {
    if (!_isModelLoaded || _currentMode != InferenceMode.landmark) {
      return const MediaPipeResult(
        success: false,
        error: 'Landmark model not loaded',
      );
    }

    try {
      debugPrint('ğŸ” detectLandmarks called - mode: $_currentMediaPipeMode, image: ${image != null ? 'available' : 'null'}');
      
      if (_currentMediaPipeMode == MediaPipeMode.stubMode) {
        debugPrint('ğŸ“ Using STUB MODE for landmark detection');
        // Stub ëª¨ë“œ ë˜ëŠ” null ì´ë¯¸ì§€: í…ŒìŠ¤íŠ¸ìš© ëœë“œë§ˆí¬ ë°ì´í„° ë°˜í™˜
        await Future.delayed(const Duration(milliseconds: 33)); // ~30 FPS ì‹œë®¬ë ˆì´ì…˜
        
        // ì† ì¤‘ì•™ ìœ„ì¹˜ì— ëª‡ ê°œì˜ í…ŒìŠ¤íŠ¸ ëœë“œë§ˆí¬ ìƒì„±
        final testLandmarks = <Map<String, double>>[];
        for (int i = 0; i < 21; i++) {
          // í™”ë©´ ì¤‘ì•™ ì£¼ë³€ì— ëœë“œë§ˆí¬ ë°°ì¹˜
          final x = 0.4 + (i % 5) * 0.04; // 0.4 ~ 0.56 ë²”ìœ„
          final y = 0.3 + (i ~/ 5) * 0.08; // 0.3 ~ 0.62 ë²”ìœ„
          testLandmarks.add({
            'x': x,
            'y': y,
            'z': 0.0,
          });
        }
        
        return MediaPipeResult(
          success: true,
          data: {
            'result': {
              'landmarks': testLandmarks,
              'detected': true,
              'confidence': 0.8,
              'validLandmarks': 21,
            }
          },
        );
      }

      // MediaPipe ëª¨ë“œ (Full ë˜ëŠ” Manual Loading)
      if (_currentMediaPipeMode == MediaPipeMode.fullMediaPipe) {
        debugPrint('ğŸš€ Using FULL MEDIAPIPE MODE for landmark detection');
      } else {
        debugPrint('ğŸ”§ Using MANUAL LOADING MODE for landmark detection');
      }
      
      if (image == null) {
        debugPrint('ğŸ¥ Camera image is null, capturing real video frame...');
        
        try {
          // ì›¹ ì¹´ë©”ë¼ì—ì„œ ì‹¤ì‹œê°„ í”„ë ˆì„ ìº¡ì²˜
          final frameData = js.context.callMethod('captureVideoFrame');
          
          if (frameData == null) {
            // í”„ë ˆì„ ìº¡ì²˜ ì‹¤íŒ¨ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
            return const MediaPipeResult(
              success: true,
              data: {
                'result': {
                  'landmarks': [],
                  'detected': false,
                  'confidence': 0.0,
                  'validLandmarks': 0,
                }
              },
            );
          }
          
          // ìº¡ì²˜ëœ í”„ë ˆì„ ì •ë³´ ì¶”ì¶œ
          final width = frameData['width'];
          final height = frameData['height'];
          
          // RGBAë¥¼ grayscaleë¡œ ë³€í™˜
          final grayscaleData = js.context.callMethod('convertToGrayscale', [frameData]);
          
          // MediaPipe ì²˜ë¦¬
          js.context.callMethod('detectHandLandmarks', [
            grayscaleData,
            width,
            height,
          ]);
          
        } catch (e) {
          debugPrint('âŒ Error capturing video frame: $e');
          // ì—ëŸ¬ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
          return const MediaPipeResult(
            success: true,
            data: {
              'result': {
                'landmarks': [],
                'detected': false,
                'confidence': 0.0,
                'validLandmarks': 0,
              }
            },
          );
        }
      }
      
      // imageê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê¸°ì¡´ ë¡œì§ ì‹¤í–‰
      dynamic callResult = 'pending';
      if (image != null) {
        final imageBytes = image.planes[0].bytes;
        
        // JavaScript í•¨ìˆ˜ í˜¸ì¶œ (ë™ê¸°ì‹ wrapper ì‚¬ìš©)
        callResult = js.context.callMethod('detectHandLandmarks', [
          imageBytes,
          image.width,
          image.height,
        ]);
      }
      
      if (callResult.toString() == 'pending') {
        // ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¼ (ìµœëŒ€ 5ì´ˆ)
        String? resultJson;
        for (int i = 0; i < 50; i++) {
          await Future.delayed(const Duration(milliseconds: 100));
          
          final result = js.context['lastDetectionResult'];
          if (result != null) {
            resultJson = result.toString();
            // ê²°ê³¼ë¥¼ ì½ì—ˆìœ¼ë¯€ë¡œ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
            js.context['lastDetectionResult'] = null;
            break;
          }
        }
        
        if (resultJson == null) {
          throw Exception('Detection timeout - no result from JavaScript');
        }
        
        final result = json.decode(resultJson);
        
        if (result['success'] == true) {
          return MediaPipeResult(
            success: true,
            data: Map<String, dynamic>.from(result),
          );
        } else {
          return MediaPipeResult(
            success: false,
            error: result['error'] ?? 'Unknown error',
          );
        }
      } else {
        // ì¦‰ì‹œ ê²°ê³¼ê°€ ë°˜í™˜ëœ ê²½ìš° (ì˜¤ë¥˜ ë“±)
        final result = json.decode(callResult.toString());
        
        if (result['success'] == true) {
          return MediaPipeResult(
            success: true,
            data: Map<String, dynamic>.from(result),
          );
        } else {
          return MediaPipeResult(
            success: false,
            error: result['error'] ?? 'Unknown error',
          );
        }
      }
    } catch (e) {
      return MediaPipeResult(
        success: false,
        error: 'Web landmark detection failed: $e',
      );
    }
  }

  @override
  Future<MediaPipeResult> recognizeGesture({
    required CameraImage? image,
  }) async {
    if (!_isModelLoaded || _currentMode != InferenceMode.gesture) {
      return const MediaPipeResult(
        success: false,
        error: 'Gesture model not loaded',
      );
    }

    try {
      if (_currentMediaPipeMode == MediaPipeMode.stubMode) {
        debugPrint('ğŸ“ Using STUB MODE for gesture recognition');
        // Stub ëª¨ë“œ: í…ŒìŠ¤íŠ¸ìš© ì œìŠ¤ì²˜ ë°ì´í„° ë°˜í™˜
        await Future.delayed(const Duration(milliseconds: 33)); // ~30 FPS ì‹œë®¬ë ˆì´ì…˜
        
        // ì† ì¤‘ì•™ ìœ„ì¹˜ì— í…ŒìŠ¤íŠ¸ ëœë“œë§ˆí¬ ìƒì„±
        final testLandmarks = <Map<String, double>>[];
        for (int i = 0; i < 21; i++) {
          final x = 0.4 + (i % 5) * 0.04; // 0.4 ~ 0.56 ë²”ìœ„
          final y = 0.3 + (i ~/ 5) * 0.08; // 0.3 ~ 0.62 ë²”ìœ„
          testLandmarks.add({
            'x': x,
            'y': y,
            'z': 0.0,
          });
        }
        
        // í…ŒìŠ¤íŠ¸ ì œìŠ¤ì²˜ ë°ì´í„°
        final testGestures = [
          {
            'categoryName': 'Open_Palm',
            'score': 0.85,
          }
        ];
        
        return MediaPipeResult(
          success: true,
          data: {
            'result': {
              'gestures': testGestures,
              'landmarks': [testLandmarks], // 3ì°¨ì› ë°°ì—´ í˜•íƒœ
              'handedness': [
                {
                  'categoryName': 'Right',
                  'score': 0.9,
                }
              ],
              'detected': true,
            }
          },
        );
      }

      // MediaPipe ëª¨ë“œ (Full ë˜ëŠ” Manual Loading)
      if (_currentMediaPipeMode == MediaPipeMode.fullMediaPipe) {
        debugPrint('ğŸš€ Using FULL MEDIAPIPE MODE for gesture recognition');
      } else {
        debugPrint('ğŸ”§ Using MANUAL LOADING MODE for gesture recognition');
      }
      
      if (image == null) {
        debugPrint('ğŸ¥ Camera image is null, capturing real video frame for gesture...');
        
        try {
          // ì›¹ ì¹´ë©”ë¼ì—ì„œ ì‹¤ì‹œê°„ í”„ë ˆì„ ìº¡ì²˜
          final frameData = js.context.callMethod('captureVideoFrame');
          
          if (frameData != null) {
            final width = frameData['width'];
            final height = frameData['height'];
            
            // RGBAë¥¼ grayscaleë¡œ ë³€í™˜
            final grayscaleData = js.context.callMethod('convertToGrayscale', [frameData]);
            
            // MediaPipe ì²˜ë¦¬
            js.context.callMethod('recognizeGesture', [
              grayscaleData,
              width,
              height,
            ]);
          }
        } catch (e) {
          debugPrint('âŒ Error capturing video frame for gesture: $e');
        }
      }
      
      // imageê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ê¸°ì¡´ ë¡œì§ ì‹¤í–‰
      dynamic callResult = 'pending'; // ê¸°ë³¸ê°’ ì„¤ì •
      if (image != null) {
        final imageBytes = image.planes[0].bytes;
        
        // JavaScript í•¨ìˆ˜ í˜¸ì¶œ (ë™ê¸°ì‹ wrapper ì‚¬ìš©)
        callResult = js.context.callMethod('recognizeGesture', [
          imageBytes,
          image.width,
          image.height,
        ]);
      }
      
      if (callResult.toString() == 'pending') {
        // ë¹„ë™ê¸° ì²˜ë¦¬ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦¼ (ìµœëŒ€ 5ì´ˆ)
        String? resultJson;
        for (int i = 0; i < 50; i++) {
          await Future.delayed(const Duration(milliseconds: 100));
          
          final result = js.context['lastGestureResult'];
          if (result != null) {
            resultJson = result.toString();
            // ê²°ê³¼ë¥¼ ì½ì—ˆìœ¼ë¯€ë¡œ ì „ì—­ ë³€ìˆ˜ ì´ˆê¸°í™”
            js.context['lastGestureResult'] = null;
            break;
          }
        }
        
        if (resultJson == null) {
          throw Exception('Gesture recognition timeout - no result from JavaScript');
        }
        
        final result = json.decode(resultJson);
        
        if (result['success'] == true) {
          return MediaPipeResult(
            success: true,
            data: Map<String, dynamic>.from(result),
          );
        } else {
          return MediaPipeResult(
            success: false,
            error: result['error'] ?? 'Unknown error',
          );
        }
      } else {
        // ì¦‰ì‹œ ê²°ê³¼ê°€ ë°˜í™˜ëœ ê²½ìš° (ì˜¤ë¥˜ ë“±)
        final result = json.decode(callResult.toString());
        
        if (result['success'] == true) {
          return MediaPipeResult(
            success: true,
            data: Map<String, dynamic>.from(result),
          );
        } else {
          return MediaPipeResult(
            success: false,
            error: result['error'] ?? 'Unknown error',
          );
        }
      }
    } catch (e) {
      return MediaPipeResult(
        success: false,
        error: 'Web gesture recognition failed: $e',
      );
    }
  }

  @override
  Future<void> dispose() async {
    try {
      // JavaScript MediaPipe ë¦¬ì†ŒìŠ¤ ì •ë¦¬
      js.context.callMethod('disposeMediaPipe');
    } catch (e) {
      // ì—ëŸ¬ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
    }
    
    _isModelLoaded = false;
  }

  @override
  bool get isModelLoaded => _isModelLoaded;

  @override
  InferenceMode get currentMode => _currentMode;
}